{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA_Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfvfg=pd.read_csv(\"test.csv\",parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfvfg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.read_csv(\"train.csv\", parse_dates=['timestamp'])\n",
    "mf=pd.read_csv(\"macro.csv\",parse_dates=['timestamp'])\n",
    "\n",
    "df_test=pd.read_csv(\"test.csv\",parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_mf=pd.merge(df_test,mf,how='left',on='timestamp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.read_csv(\"train.csv\", parse_dates=['timestamp'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# after merging both machro and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mf_train=pd.merge(df_train,mf,how='left',on='timestamp')\n",
    "df_mf_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mf_train['state'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mf_train.loc[df_mf_train['cafe_count_500']==0,'cafe_sum_500_min_price_avg'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mf_train['cafe_sum_500_min_price_avg'].isna().sum()\n",
    "13281-297"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#total we have 391 features \n",
    "#out of which 292 features are meata features for house and remaining 99 features are macro econmic features set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How is price doc distributed ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.distplot(df['price_doc'],kde_kws={\"cumulative\":\"TRUE\",\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"}, hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\n",
    "                            #\"alpha\": 1, \"color\": \"g\"})\n",
    "sns.violinplot((df_mf_train['price_doc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "ax = sns.distplot((np.log(df['price_doc'])), fit=norm, kde=True,hist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we are making prices log transform and it looks like it near log normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['price_doc'].values,kde_kws={\"cumulative\":\"TRUE\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the price are not widely distributed they look almost tight bounded after log transform are in the range l4 amd 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(90,100,1):\n",
    "    var =df[\"price_doc\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(i,(var[int(len(var)*(float(i)/100))])))\n",
    "print (\"100 percentile value is \",(var[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "19200000-16900000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "24606918-19200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,11,1):\n",
    "    var =df[\"price_doc\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(i,(var[int(len(var)*(float(i)/100))])))\n",
    "print (\"10 percentile value is \",np.log(var[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#16.88 could be the limiting point for outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# percentage of missing Values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nul={}\n",
    "for i in df_mf_train.columns:\n",
    "    nl=(df_mf_train[i].isna().sum()/30471)*100\n",
    "    if nl!=0:\n",
    "        nul[i]=nl\n",
    "        #print(i,\":\",nl)\n",
    "nul_sort={k: v for k, v in sorted(nul.items(), key=lambda item: item[1])}\n",
    "nul_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['build_count_1971-1995']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nul={}\n",
    "for i in df_mf_train.columns:\n",
    "    nl=(df_mf_train[i].isna().sum()/30471)*100\n",
    "    if nl!=0:\n",
    "        nul[i]=nl\n",
    "        #print(i,\":\",nl)\n",
    "nul_sort={k: v for k, v in sorted(nul.items(), key=lambda item: item[1])}\n",
    "x=nul_sort.keys()\n",
    "y=nul_sort.values()\n",
    "plt.figure(figsize=(10,50)) # Setting the figure size\n",
    "ax = plt.axes()\n",
    "ax.set_facecolor(\"#ECF0F1\") # Setting the background color by specifying the HEX Code\n",
    "ind = np.arange(93)\n",
    "bar=plt.barh(ind,y,color = '#FFA726')\n",
    "plt.xlabel(r'features')\n",
    "plt.ylabel(r'missing_values')\n",
    "ax.set_yticks(ind)\n",
    "ax.set_yticklabels(x, rotation='horizontal')\n",
    "plt.xticks(rotation=90, horizontalalignment='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#total 93 missing features\n",
    "#out of which 'provision_retail_space_modern_sqm','provision_retail_space_sqm' are most missing features in the whole data set\n",
    "#state tell us about the conditon of the building\n",
    "#train data file features  missing values are 51\n",
    "#and remaining meta missing features are 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "meta_chars=df_mf_train[['full_sq','life_sq','floor','max_floor','material','area_m','num_room','kitch_sq','state','price_doc']]\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(meta_chars.corr(), cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook') \n",
    "plt.figure(figsize=(10,14))\n",
    "\n",
    "grouped_df = df.groupby('micex_rgbi_tr')['price_doc'].aggregate(np.median).reset_index()\n",
    "\n",
    "\n",
    "    sns.lineplot( y='price_doc',x='micex_rgbi_tr',data=grouped_df)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"median_price _share_depending on the floor\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we could see he full_sq and life_sq are highly corelated with respetive to other features muncipality area is neagtively corelated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## floor and MAX_FLOOR detailing and missing _values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook') \n",
    "plt.figure(figsize=(10,14))\n",
    "\n",
    "grouped_df = df.groupby('floor')['price_doc'].aggregate(np.median).reset_index()\n",
    "\n",
    "\n",
    "sns.pointplot( y='price_doc',x='floor',data=grouped_df)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"median_price _share_depending on the floor\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#the single store i.e ground floor houses are compartively high in price\n",
    "#and the prices seems to after the 18 floor and need to see distibution of the floor in the next plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook') \n",
    "plt.figure(figsize=(10,14))\n",
    "\n",
    "\n",
    "\n",
    "sns.distplot(df['floor'])\n",
    "plt.title('dist_of_floor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#we could see the that most of floors are in a the range of 0 to 30\n",
    "#beyond 29 the no of houses are vey less and prices steep only 41 houses present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['floor']>=29,'floor'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar thing we do for max_floor\n",
    "\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook') \n",
    "plt.figure(figsize=(10,14))\n",
    "\n",
    "grouped_df = df.groupby('max_floor')['price_doc'].aggregate(np.median).reset_index()\n",
    "\n",
    "\n",
    "sns.pointplot( y='price_doc',x='max_floor',data=grouped_df)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"median_price _share_depending on the max_floor\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#we could see heavy fluction and couldnt get any sense of the data\n",
    "# we better cross check with the floor and max_floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['max_floor']-df['floor']<0][['floor','max_floor']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#we see 1493 are miss placed max_floors we try to swap\n",
    "#we have nearly 0.6% of missing values in floor and 31.5% missing values for max_floor so we cant average it.\n",
    "#we pre_process in feature column"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# so_here we better fill the values of max_floor with 1 and check the condotion and swap the values in preprocess form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DESCRIPTION OF CATEGORICAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 15 categories features\n",
    "dtype_df = df_mf_train.dtypes.reset_index()\n",
    "dtype_df.columns = [\"Count\", \"Column Type\"]\n",
    "dtype_df.groupby(\"Column Type\").aggregate('count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_cat_feat=dtype_df[(dtype_df['Column Type'])=='object']['Count']\n",
    "mf[mf_cat_feat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we have 18 categorical features and remaining 372 continuous valuess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat=dtype_df[(dtype_df['Column Type'])=='object']['Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_mf_train[cat_feat]:\n",
    "    print(col,\"               \",len(df_mf_train[col].unique()),\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mf_train['modern_education_share'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mf_train['child_on_acc_pre_school'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mf_train['old_education_build_share'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AREA OF DIFFERENT PARTS OF THE HOUSE, distributuions and there realtion with target, NUM OF ROOMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook') \n",
    "plt.figure(figsize=(10,14))\n",
    "\n",
    "grouped_df = df.groupby('num_room')['price_doc'].aggregate(np.median).reset_index()\n",
    "\n",
    "\n",
    "sns.pointplot( y='price_doc',x='num_room',data=grouped_df)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"median_price _share_depending on the floor\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#the num_room seems to rise and reached top at 9th floor and tend to fall down at 10the and 17tth we need to see there prportion in the next plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook') \n",
    "plt.figure(figsize=(10,14))\n",
    "\n",
    "\n",
    "\n",
    "sns.countplot(df['num_room'])\n",
    "plt.title('dist_of_floor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# so no need to worry about the large no of rooms as it may be outlier or exceptional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(90,100,1):\n",
    "    var =df[\"full_sq\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(i,(var[int(len(var)*(float(i)/100))])))\n",
    "print (\"100 percentile value is \",(var[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(95,100,.1):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0.0,1.0,0.1):\n",
    "    var =df[\"full_sq\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(99+i,(var[int(len(var)*(float(99+i)/100))])))\n",
    "print (\"100 percentile value is \",(var[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0.0,1.0,0.1):\n",
    "    var =df[\"full_sq\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(0+i,(var[int(len(var)*(float(0+i)/100))])))\n",
    "print (\"100 percentile value is \",(var[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10,1):\n",
    "    var =df[\"full_sq\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(i,(var[int(len(var)*(float(i)/100))])))\n",
    "print (\"100 percentile value is \",(var[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.full_sq == 5326.0, 'full_sq'] = 53\n",
    "df.loc[df.full_sq == 729.0, 'full_sq'] = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=(df.life_sq.values), y=np.log(df.price_doc.values))\n",
    "plt.xlabel(\"life_area\")\n",
    "plt.ylabel(\"price_of_house\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it seems to correlate well with the area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=np.log(df.full_sq.values), y=np.log(df.price_doc.values))\n",
    "plt.xlabel(\"total_area\")\n",
    "plt.ylabel(\"price_of_house\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it also seems to corellate more well than the life_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we could see that full_sq and total area are most important features as they are proprtional to full_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=((df.kremlin_km.values)-df.kremlin_km.min(axis=0))/(df.kremlin_km.max(axis=0)-df.kremlin_km.min(axis=0))\n",
    "y=((df.price_doc.values)-df.price_doc.min(axis=0))/(df.price_doc.max(axis=0)-df.price_doc.min(axis=0))\n",
    "plt.scatter(x=x, y=y)\n",
    "plt.xlabel(\"city_center\")\n",
    "plt.ylabel(\"price_of_house\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#may be due to non-linear relationship the we couldnt see any INFO here so we have tried with spearman rank corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.spearmanr(df.kremlin_km.values,df.price_doc.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from spearman correlation we can conclude that city center is inversely proportinal values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# price values and city center are inversely corellated"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=(df.kremlin_km.values)-df.kremlin_km.mean()/df.kremlin_km.std()\n",
    "y=(df.price_doc.values)-df.kremlin_km.mean()/df.kremlin_km.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.price_doc.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.kremlin_km.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=((df.kremlin_km.values)-df.kremlin_km.min(axis=0))/(df.kremlin_km.max(axis=0)-df.kremlin_km.min(axis=0))\n",
    "y=((df.price_doc.values)-df.price_doc.min(axis=0))/(df.price_doc.max(axis=0)-df.price_doc.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD_YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['build_year'].isna(),'state'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['state'].isna(),'build_year'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using max and min changed sum values\n",
    "df.loc[df['build_year'] < 1700, 'build_year'] = np.nan\n",
    "df.loc[df['build_year'] == 20052009.0, 'build_year'] = 2009\n",
    "df.loc[df['build_year'] == 4965, 'build_year'] = 1965\n",
    "df.loc[df.full_sq == 5326.0, 'full_sq'] = 53\n",
    "df.loc[df.full_sq == 729.0, 'full_sq'] = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('build_year')['price_doc'].aggregate(np.median).reset_index()\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.lineplot(grouped_df.build_year.values, (grouped_df.price_doc.values), alpha=0.8)\n",
    "plt.ylabel('Median Price', fontsize=12)\n",
    "plt.xlabel('build_year', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# seems the prices are nominal after 1960\n",
    "#and are overpriced before 1960\n",
    "#after 2015 prices started to rise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['build_year']>2015,'build_year'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATERIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['material'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 as nan_values\n",
    "df1=df\n",
    "df1.loc[df1['material'].isna(),'material']=0\n",
    "df1['material'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we assume here 0 has nan_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('material')['price_doc'].aggregate(np.median).reset_index()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.pointplot(grouped_df.material.values, grouped_df.price_doc.values, alpha=0.8)\n",
    "plt.ylabel('Median Price', fontsize=12)\n",
    "plt.xlabel('material', fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[df1['material']==0,'material']=np.nan\n",
    "\n",
    "grouped_df1 = df1.groupby('material')['price_doc'].aggregate(np.median).reset_index()\n",
    "\n",
    "sns.pointplot(grouped_df1.material.values, grouped_df1.price_doc.values, alpha=0.8)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#from_both_plots it is shown that it is better to group of 0 with shows less prices based o that missing values are replaced with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ecology zone of the area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x1=df.loc[df[\"ecology\"]=='excellent','price_doc']\n",
    "x2=df.loc[df[\"ecology\"]=='good']['price_doc']\n",
    "x3=df.loc[df[\"ecology\"]=='satisfactory','price_doc']\n",
    "x4=df.loc[df[\"ecology\"]=='poor']['price_doc']\n",
    "x5=df.loc[df[\"ecology\"]=='no data','price_doc']\n",
    "\n",
    "\n",
    "sns.distplot((x1))\n",
    "sns.distplot((x2))\n",
    "sns.distplot((x3))\n",
    "sns.distplot((x4))\n",
    "sns.distplot((x5))\n",
    "plt.legend(title='price_share', loc='upper right', labels=['excellent', 'good','satisfactory','poor','no data'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#the missing values which has labeled as \"NO DATA\" shown a great variance in the above plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# population Feature of different age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.spearmanr(np.log(df.micex_rgbi_tr.values),np.log(df.price_doc.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log(df['micex_rgbi_tr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df=df.iloc[:,41:67]\n",
    "pop_df['price_doc']=df.price_doc.values\n",
    "#phi_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(pop_df.corr(), cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#we coulde have minimum corelation between the features but it is always a positive corelation but there is also corelation between #the young_male to 0_17_fe-MALE which we need to drop many of the features here\n",
    "\n",
    "#so by this the more the population the price may go up and the working employees may rise the bar of the male people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance to various Place Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_df=df.iloc[:,85:152]\n",
    "dis_df['price_doc']=df.price_doc.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "plt.figure(figsize=(30,50))\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(dis_df.corr(), cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.xticks(fontsize =20)\n",
    "plt.yticks(fontsize =20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#as we coulde see some of the features are neagtivley corelated that could be with respect to the INDUSTRIES, FACTORIES \n",
    "which are located far away\n",
    "\n",
    "#and some of the city attractions nearby roads, railways,cafes are could be postively corelated with itself may be some of them should be removed\n",
    "\n",
    "\n",
    "#many of this features are higly corelated between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#x=['oil_urals','gdp_quart','gdp_quart_growth','cpi','ppi','gdp_deflator','balance_trade','balance_trade_growth','usdrub','eurrub','brent','gdp_annual','gdp_annual_growth']\n",
    "y='price_doc'\n",
    "dis_df=df.iloc[:,85:152]\n",
    "dis_df['price_doc']=df.price_doc.values\n",
    "from scipy import stats\n",
    "for i in dis_df.columns[1:]:\n",
    "    print(i,\":\",stats.spearmanr(df[i],df[y])[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#As the distance increase price also tend to drop in neagtive corelation\n",
    "#these are highly neagtively correlated\n",
    "#swim_pool_km\n",
    "#nuclear_reactor_km\n",
    "#kremlin_km\n",
    "#bulvar_ring_km\n",
    "#sadovoe_km\n",
    "#ttk_km\n",
    "#metro_km_avto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_df.isna().sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ament_df=df.iloc[:,153:292]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ament_df.isna().sum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ament_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.countplot(x=\"sub_area\", data=df_train)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xlabel('sub_area', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRICE SHARE OF VARIOUS CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_p=df.loc[df['product_type']=='Investment']['price_doc']\n",
    "x_i=df.loc[df['product_type']!='Investment','price_doc']\n",
    "sns.distplot(np.log(x_p))\n",
    "sns.distplot(np.log(x_i))\n",
    "plt.legend(title='price_share', loc='upper right', labels=['Investment', 'Ownerocupier'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#it is not perfectly differnitable but they is some variance between two types owner occupied are compartevely less\n",
    "#so it is better to create seperate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_area={k: v for k, v in sorted(sub_dict.items(), key=lambda item: item[1],reverse=True)}\n",
    "sub_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://datascience.stackexchange.com/questions/48035/how-to-show-percentage-text-next-to-the-horizontal-bars-in-matplotlib\n",
    "fig, ax= plt.subplots(figsize =(12,40))\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook') \n",
    "grouped_df = df.groupby('sub_area')['price_doc'].aggregate(np.median).reset_index()\n",
    "\n",
    "\n",
    "ax=sns.barplot(palette=\"Dark2\",ax=ax, x='price_doc',y='sub_area',data=grouped_df,orient='H')\n",
    "total=len(df['sub_area'])\n",
    "plt.fontsize =(35)\n",
    "for p in ax.patches:\n",
    "    percentage ='{:,.0f}'.format(p.get_width())\n",
    "    width, height =p.get_width(),p.get_height()\n",
    "    x=p.get_x()+width+0.02\n",
    "    y=p.get_y()+height/2\n",
    "    ax.annotate(percentage,(x,y))\n",
    "\n",
    "plt.xticks(rotation =0,fontsize =18)\n",
    "plt.yticks(rotation =0,fontsize =20)\n",
    "\n",
    "plt.title(\"median price of the areas\")\n",
    "plt.xlabel ('price_share',fontsize =24)\n",
    "plt.ylabel ('sub_areas',fontsize =24)\n",
    "\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#some of the areas of the sub_area has very high median price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('sub_area')['price_doc'].aggregate(np.median).reset_index()\n",
    "plt.figure(figsize=(24,8))\n",
    "sns.lineplot(grouped_df.sub_area.values, grouped_df.price_doc.values, alpha=0.8)\n",
    "plt.ylabel('Median Price', fontsize=12)\n",
    "plt.xlabel('sub_area', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## the price of the median price we could see there is much fluctuation in the data with respect to sub_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('timestamp')['target'].aggregate(np.median).reset_index()\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.lineplot(grouped_df.timestamp.values, np.log(grouped_df.target.values), alpha=0.8)\n",
    "plt.ylabel('Median Price', fontsize=12)\n",
    "plt.xlabel('timestamp', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the prices seems to go_up as the time progresses we need to zoom in and see the plots for each year\n",
    "# we will divide the years into 2011, to 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df['timestamp']=df['timestamp'].astype(str)\n",
    "df['year']=df['timestamp'].apply(lambda x: x[:4])\n",
    "df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "201208-201108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=df.loc[df.year=='2011' ,'price_doc']\n",
    "y2=df.loc[df.year=='2012','price_doc']\n",
    "y3=df.loc[df.year=='2013','price_doc']\n",
    "y4=df.loc[df.year=='2014','price_doc']\n",
    "y5=df.loc[df.year=='2015','price_doc']\n",
    "sns.distplot(np.log(y1))\n",
    "sns.distplot(np.log(y2))\n",
    "sns.distplot(np.log(y3))\n",
    "sns.distplot(np.log(y4))\n",
    "sns.distplot(np.log(y5))\n",
    "plt.legend(title='price_share', loc='upper right', labels=['2011','2012','2013','2014','2015'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the distribution of prices seems to be same every where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('timestamp')['employment'].aggregate(np.median).reset_index()\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.lineplot(grouped_df.timestamp.values, grouped_df.employment.values, alpha=0.8)\n",
    "plt.ylabel('Median Price', fontsize=12)\n",
    "plt.xlabel('sub_area', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As the time progress employenet gorwn which seems the prices also mmight have raised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook') \n",
    "plt.figure(figsize=(10,14))\n",
    "\n",
    "grouped_df = df.groupby('gdp_quart')['grp'].aggregate(np.median).reset_index()\n",
    "\n",
    "\n",
    "sns.pointplot( y='gdp_quart',x='grp',data=df)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"median_price _share_depending on the floor\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#based on this some of the misssing values are made imputed with max_value\n",
    "#and some values are imputed with min _value\n",
    "#and some imputed with median values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GDP\n",
    "grouped_df = df.groupby('gdp_deflator')['price_doc'].aggregate(np.median).reset_index()\n",
    "plt.figure(figsize=(24,8))\n",
    "sns.lineplot(grouped_df.gdp_deflator.values, grouped_df.price_doc.values, alpha=0.8)\n",
    "plt.ylabel('Median Price', fontsize=12)\n",
    "plt.xlabel('gdp', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deflator_shows positve trend towards as rise in PRICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_mf_train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "oil_urals:                   Crude Oil Urals ($/bbl)\n",
    "gdp_quart:                 GDP\n",
    "gdp_quart_growth:       Real GDP growth\n",
    "cpi:                                Inflation -  Consumer Price Index Growth\n",
    "ppi:                                  Inflation - Producer Price index Growth\n",
    "gdp_deflator:                     Inflation - GDP deflator\n",
    "balance_trade:                    Trade surplus\n",
    "Balance_trade_growth:           Trade balance (as a percentage of previous year)\n",
    "Usdrub:                                   Ruble/USD exchange rate\n",
    "Eurrub:                                     Ruble/EUR exchange rate\n",
    "brent:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf=df[['oil_urals','gdp_quart','gdp_quart_growth','cpi','ppi','gdp_deflator','balance_trade','balance_trade_growth','usdrub','eurrub','brent','gdp_annual','gdp_annual_growth','price_doc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(mdf.corr(), cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#it shown little postitve relation for foreighn currency and for CPI AND PPI and shown -ve relaion oil_urals and GDP_quart_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=['oil_urals','gdp_quart','gdp_quart_growth','cpi','ppi','gdp_deflator','balance_trade','balance_trade_growth','usdrub','eurrub','brent','gdp_annual','gdp_annual_growth']\n",
    "y='price_doc'\n",
    "from scipy import stats\n",
    "for i in mf.columns[1:]:\n",
    "    print(i,\":\",stats.spearmanr(df[i],df[y])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# before-preprocess modelling just filled values with 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mf_train.fillna(0,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PREPROCESSING_WILL_BE_CONTINUED_IN_YOUR_NEXT_BOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}